{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdN/2Tbs49/01maZT45GMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m2qaderi/msci-nlp-w22/blob/master/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fZYzO_UYVPf",
        "outputId": "680c47a0-aa47-4164-e419-c7b3d8371ae6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim as gensim\n",
        "import keras as keras\n",
        "import numpy as numpy\n",
        "import sklearn as sklearn\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "import re\n",
        "import random\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "vqvNIs0BLmqm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/MyDrive/neg.txt\") as f: \n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "akEW5x3OipL0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x = text.split(\" \")\n",
        "\n",
        "\n",
        "#out = open(\"out.csv\", \"w\")\n",
        "#for element in x:\n",
        " #   out.write(element + \" \")\n",
        "#out.close()\n",
        "\n",
        "\n",
        "#print(x[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yalPpsRli0VY",
        "outputId": "5ad1c328-442e-4694-d581-0d849a657be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'bought', 'this', 'when', 'I', 'bought', 'the', 'pop', 'maker.\\nAs', 'for', '\"pop', 'embellishing\"', 'well,', 'that', \"wasn't\", 'too', 'hard', 'to', 'figure', 'out,', \"either.\\nI'd\", 'save', 'the', 'money', 'and', 'spend', 'it', 'instead', 'on', 'extra', 'pop', 'sticks,', 'which', 'seem', 'to', 'disappear', 'the', 'way', 'socks', \"do.\\ndidn't\", 'really', 'care', 'many', 'of', 'the', 'cakes', 'at', 'all.\\nnot', 'up', 'to', 'normal', 'standing', 'for', 'wilton', 'yearbooks', 'of', 'the', 'past.\\nBuy', 'a', 'Wilton', 'magazine', 'for', 'less', 'money', 'and', 'get', 'more', 'ideas', 'and', 'instructions', 'for', 'your', 'investment.\\nBag', 'tore', 'with', 'almost', 'nothing', 'in', 'it', '-', 'Just', 'caught', 'the', 'corner', 'of', 'a', 'small', 'cracker', 'box', 'and', 'that', 'was', 'that.\\nThis', 'machine', 'is', 'exactly', 'what', 'the', 'name', 'says']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(text.split())"
      ],
      "metadata": {
        "id": "zLLPoPaeV7VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing special characters and splitting into tokens (by word)\n",
        "# Includes stopwords\n",
        "\n",
        "new_string = re.sub('[!\"#$%&()*+/:;<=>@[\\\\]^`{|}~\\t\\n]', '', text)\n",
        "x = new_string.replace(\".\", '.\\n')\n",
        "lower = x.lower()\n",
        "final = lower.split(\" \")\n",
        "\n",
        "out = open(\"out.csv\", \"w\")\n",
        "for element in final:\n",
        "    out.write(element + \" \\n\")\n",
        "out.close()\n",
        "\n",
        "print(final[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrHg7qdHU8Bj",
        "outputId": "7fd8ca36-04e6-4daf-f653-2fdbfc68f65e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'bought', 'this', 'when', 'i', 'bought', 'the', 'pop', 'maker.\\nas', 'for', 'pop', 'embellishing', 'well,', 'that', \"wasn't\", 'too', 'hard', 'to', 'figure', 'out,', \"either.\\ni'd\", 'save', 'the', 'money', 'and', 'spend', 'it', 'instead', 'on', 'extra', 'pop', 'sticks,', 'which', 'seem', 'to', 'disappear', 'the', 'way', 'socks', \"do.\\ndidn't\", 'really', 'care', 'many', 'of', 'the', 'cakes', 'at', 'all.\\nnot', 'up', 'to', 'normal', 'standing', 'for', 'wilton', 'yearbooks', 'of', 'the', 'past.\\nbuy', 'a', 'wilton', 'magazine', 'for', 'less', 'money', 'and', 'get', 'more', 'ideas', 'and', 'instructions', 'for', 'your', 'investment.\\nbag', 'tore', 'with', 'almost', 'nothing', 'in', 'it', '-', 'just', 'caught', 'the', 'corner', 'of', 'a', 'small', 'cracker', 'box', 'and', 'that', 'was', 'that.\\nthis', 'machine', 'is', 'exactly', 'what', 'the', 'name', 'says']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data in train and test\n",
        "\n",
        "import sklearn.model_selection\n",
        "\n",
        "a = list(lower.split(\" \"))\n",
        "b = random.shuffle(x)\n",
        "train_dataset, test_dataset = sklearn.model_selection.train_test_split(a, train_size=.8, test_size=.2)\n",
        "test2_dataset, valid_dataset = sklearn.model_selection.train_test_split(test_dataset, train_size=.5, test_size=.5)\n",
        "\n",
        "\n",
        "print(train_dataset)\n",
        "print(len(train_dataset))\n",
        "\n",
        "print(test2_dataset)\n",
        "print(len(test2_dataset))\n",
        "\n",
        "print(valid_dataset)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "train = open(\"train.csv\", \"w\")\n",
        "for element in train_dataset:\n",
        "    train.write(element + \" \\n\")\n",
        "train.close()\n",
        "\n",
        "test = open(\"test.csv\", \"w\")\n",
        "for element in test2_dataset:\n",
        "    test.write(element + \" \\n\")\n",
        "test.close()\n",
        "\n",
        "val = open(\"val.csv\", \"w\")\n",
        "for element in valid_dataset:\n",
        "    val.write(element + \" \\n\")\n",
        "val.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT3i7VgUMHun",
        "outputId": "d50e8c4d-c32a-433f-9aa5-d108588107c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords (no special characters)\n",
        "\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "filtered_text = remove_stopwords(lower)\n",
        "ns = filtered_text.split(\" \")\n",
        "\n",
        "out_ns = open(\"out_ns.csv\", \"w\")\n",
        "for element in ns:\n",
        "    out_ns.write(element + \" \\n\")\n",
        "out_ns.close()\n",
        "\n",
        "print(ns[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJva5SBVovdc",
        "outputId": "7afde5f0-82a5-4271-8666-45a57e1d83c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bought', 'bought', 'pop', 'maker.', 'pop', 'embellishing', 'well,', \"wasn't\", 'hard', 'figure', 'out,', 'either.', \"i'd\", 'save', 'money', 'spend', 'instead', 'extra', 'pop', 'sticks,', 'disappear', 'way', 'socks', 'do.', \"didn't\", 'care', 'cakes', 'all.', 'normal', 'standing', 'wilton', 'yearbooks', 'past.', 'buy', 'wilton', 'magazine', 'money', 'ideas', 'instructions', 'investment.', 'bag', 'tore', '-', 'caught', 'corner', 'small', 'cracker', 'box', 'that.', 'machine', 'exactly', 'says', '-', 'speller.', 'wanted', 'definitions,', 'oh,', 'dictionary', 'ordered', 'dictionary', 'happy', '-', 'voice', 'scratchy.', 'type', 'wrong', 'word', 'in,', '34might34', 'produce', 'correct', 'word.', \"doesn't\", 'explanation', 'meaning', 'used.', 'sent', 'bk.', ',', 'factored', 'cost', 'return', 'shipping', '-', \"wasn't\", 'worth', 'return.', \"it's\", 'basically', 'coat', 'hanger', 'plastic', 'guides.', 'thing', 'going', 'portability.', 'hold', 'regular', 'sized', 'hard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting ns data in train and test\n",
        "\n",
        "import sklearn.model_selection\n",
        "\n",
        "x = list(filtered_text.split(\" \"))\n",
        "y = random.shuffle(x)\n",
        "train_dataset, test_dataset = sklearn.model_selection.train_test_split(x, train_size=.8, test_size=.2)\n",
        "test2_dataset, valid_dataset = sklearn.model_selection.train_test_split(test_dataset, train_size=.5, test_size=.5)\n",
        "\n",
        "\n",
        "print(train_dataset)\n",
        "print(len(train_dataset))\n",
        "\n",
        "print(test2_dataset)\n",
        "print(len(test2_dataset))\n",
        "\n",
        "print(valid_dataset)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "train_ns = open(\"train_ns.csv\", \"w\")\n",
        "for element in train_dataset:\n",
        "    train_ns.write(element + \" \\n\")\n",
        "train_ns.close()\n",
        "\n",
        "test_ns = open(\"test_ns.csv\", \"w\")\n",
        "for element in test2_dataset:\n",
        "    test_ns.write(element + \" \\n\")\n",
        "test_ns.close()\n",
        "\n",
        "val_ns = open(\"val_ns.csv\", \"w\")\n",
        "for element in valid_dataset:\n",
        "    val_ns.write(element + \" \\n\")\n",
        "val_ns.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "QKvj6ySluG28",
        "outputId": "3442175b-9d26-49ec-d238-d60afe0bdeec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bf32dc342029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest2_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[1;32m   2421\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
          ]
        }
      ]
    }
  ]
}